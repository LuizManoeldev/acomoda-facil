<h1 align="center" style="font-weight: bold;">Acomoda f√°cil üíª</h1>

<p align="center">
 <a href="#desenvolvimento-e-resultado">Desenvolvimento</a> ‚Ä¢ 
 <a href="#tecnologias-utilizadas">Tecnologias</a> ‚Ä¢ 
 <a href="#como-foi">Detalhamento</a> ‚Ä¢
 <a href="#arquitetura">Arquitetura</a> ‚Ä¢
 <a href="#pastas">Pastas</a> ‚Ä¢
 <a href="#instru√ß√µes">Como rodar</a>‚Ä¢
 <a href="#dificuldades-encontradas">Dificuldades</a> ‚Ä¢
 <a href="#contribuidores">Contribidores</a>
</p>


Bem-vindo √† documenta√ß√£o do sistema de previs√£o de valor de alugueis em h√≥teis, desenvolvido para aproveitar o poder do Amazon SageMaker. Este sistema √© projetado para receber dados no formato JSON e fornecer uma previs√£o classificat√≥ria dos valores de alugu√©is .


<h2 id="desenvolvimento-e-resultado"> 	üìä Desenvolvimento e resultado </h2>

- O sitema foi desenvolvido a partir do projeto de bolsas da Compass UOL/AWS. 
- A equipe se organizou em torno dos objetivos de cria√ß√£o da API e treinamento do modelo utilizando a plataforma AWS fornecida
- Com o esfor√ßo de todos na equipe, conseguimos um total de 86% de acur√°cia.


<h2 id="tecnologias-utilizadas"> üìé Tecnologias Utilizadas </h2>

### Organiza√ß√£o da equipe 

- **Trello** - Organiza√ß√£o da equipe de desenvolvimento.
- **Git** - Controle de vers√£o e elabora√ß√£o do sistema.

### API e aprendizagem de m√°quina
- **Python (3.12.3)** - Linguagem da API.
- **FastAPI** - Framework para o desenvolvimento da API.
- **uvicorn** - Servidor para aplica√ß√µes web ass√≠ncronas em Python.
- **boto3** - Biblioteca AWS SDK para interagir com os recursos.
- **scikit-learn** - Biblioteca de machine learning utilizada para ferramentas de an√°lise e modelagem de dados.
- **pydantic** - Biblioteca de valida√ß√£o de dados, tamb√©m utilizada para garantir o recebimento de dados no formato correto.
- **joblib** - Biblioteca Python utilizada para salvar e carregar modelos treinados.
- **pandas** - Biblioteca utilizada para ler e escrever dados em v√°rios formatos de arquivo.
- **XGBoost** - Biblioteca de machine learning utilizada para otimizar os processos de compress√£o de dados.
- **SageMaker** - Servi√ßo para treinar e desenvolver modelos de macinhe Learning 
- **Jupyter Notebooks** - Execu√ß√£o dos c√≥digos
### Cont√™ineres e banco de dados 
- **Docker Compose** - Plataforma para executar os cont√™ineres, melhorando o deploy e o processamento do sistema. 
- **PyMySQL (1.1.1)** - Biblioteca Python utilizada para consultas, inser√ß√µes, atualiza√ß√µes e dele√ß√µes de registros em bancos de dados MySQL.
- **S3** - Armazenar o modelo.


<h2 id="como-foi"> üîé Como Foi Alcan√ßado Este Resultado de Modelo </h2>

Primeiramente, foram selecionadas as primeiras 29 colunas para fazer o conjunto de testes (Caso queira analisar e saber como escolhemos cada coluna, voc√™ pode executar o notebook que est√° localizado nas pastas `notebooks\exploratory`). Depois, foram decididos os hiperpar√¢metros do modelo.

### Hiperpar√¢metros

- **Objective** - Foi decidido usar `multi:softmax`, pois a classifica√ß√£o poderia prever tr√™s classes distintas, conforme especificado em `num_class`.

- **Eval_metric** -
Foi escolhido `mlogloss`, pois ele √© uma m√©trica que prev√™ a efic√°cia do modelo em treinamento, caracterizado por penalizar previs√µes incorretas de forma exponencial.

- **Gamma, Lambda** -
Os valores de gamma razoavelmente alto, `0.6307...`, e o moderado de lambda, `0.138...`, foram escolhidos para evitar overfitting. Um previne a cria√ß√£o de parti√ß√µes desnecess√°rias, e o outro ajuda a adicionar regulariza√ß√£o aos pesos, mantendo o modelo simples, respectivamente.

- **Colsample_bytree** - 
O valor `0.958...` foi escolhido para permitir que a maioria das colunas seja usada em cada √°rvore, garantindo que o modelo utilize a maior parte da informa√ß√£o dispon√≠vel.

- **Eta** -
Para a taxa de aprendizado, foi escolhido um valor baixo de `0.05`, para garantir que o modelo aprenda de forma gradual, tamb√©m prevenindo overfitting.

- **Max_depth** - 
Com a cautela utilizada no `gamma` e `lambda` para evitar overfitting, decidimos arriscar um n√∫mero alto, `9`, para capturar o m√°ximo de intera√ß√µes complexas nos dados.

- **Min_child_weight** -
Ele especifica a soma m√≠nima de pesos, por isso o valor moderado de `2.62...` foi escolhido, para garantir que n√≥s filhos n√£o sejam criados a menos que contenham um n√∫mero significativo de amostras.

- **Subsample** -
Foi decidido utilizar a maior quantidade de dados de treinamento poss√≠vel, `0.95...`, mas n√£o todos, para evitar o risco de overfitting.

- **Num_round** -
Ap√≥s v√°rios testes, foi percebido que uma quantidade adequada de rodadas de boosting era 1000.

____
A conclus√£o dos hiperpar√¢metros utilizados neste modelo de XGBoost foi alcan√ßada a partir de um extenso processo de tuning. Esse processo envolveu testar v√°rias combina√ß√µes de hiperpar√¢metros para identificar a configura√ß√£o que proporcionasse a melhor acur√°cia e desempenho geral do modelo.

<h2 id="arquitetura"> 	‚úíÔ∏è Arquitetura </h2>

![Diagrama - SasgeMaker Training](image/arquitetura.png)

<h2 id="pastas"> üìÇ Pastas </h2>


```
.
‚îú‚îÄ‚îÄ api/             # Diret√≥rio que cont√©m a API do sistema.
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ src/         # C√≥digo-fonte da aplica√ß√£o, onde a l√≥gica principal est√° implementada.
‚îÇ   ‚îî‚îÄ‚îÄ main         # Ponto de entrada da aplica√ß√£o, onde a API √© inicializada.
‚îÇ¬†¬† 
‚îú‚îÄ‚îÄ data/            # Diret√≥rio que armazena os dados utilizados no sistema.
‚îÇ   ‚îú‚îÄ‚îÄ external/    # Dados externos que ser√£o utilizados para enriquecer a an√°lise.
‚îÇ   ‚îú‚îÄ‚îÄ processed/   # Dados j√° processados e prontos para uso nos modelos.
‚îÇ   ‚îî‚îÄ‚îÄ raw/         # Dados brutos, ainda sem processamento.
‚îú‚îÄ‚îÄ environment/     # Diret√≥rio para gerenciar ambientes virtuais ou configura√ß√µes espec√≠ficas.
‚îú‚îÄ‚îÄ notebooks/       # Diret√≥rio que cont√©m os Jupyter Notebooks para an√°lise e modelagem.
‚îÇ¬†  ‚îú‚îÄ‚îÄ exploratory/ # Notebooks para explora√ß√£o inicial dos dados.
‚îÇ¬†  ‚îî‚îÄ‚îÄ modeling/    # Notebooks focados na constru√ß√£o e avalia√ß√£o dos modelos de machine learning.
‚îú‚îÄ‚îÄscripts_ec2       # Scripts que ser√£o executados na inst√¢ncia EC2. 
‚îî‚îÄ‚îÄ Dockerfile       # Arquivo de configura√ß√£o para criar a imagem Docker da API.
```

<h2 id="instru√ß√µes"> üìò Instru√ß√µes de Como Rodar </h2>

### Pr√©-requisitos
- Git
- Python (3.12.*)
- Docker
- Conta AWS
- AWS CLI
___
### Passo a Passo

#### I. Clone o Reposit√≥rio:
   ```bash
   git clone -b grupo-2 --single-branch https://github.com/Compass-pb-aws-2024-MAIO-A/sprints-4-5-pb-aws-maio.git
   ```

#### II. Navegue at√© o Diret√≥rio:
   ```bash 
   cd sprints-4-5-pb-aws-maio
   ```
#### III. Cria√ß√£o do Arquivo .env:
Use como exemplo o arquivo `environment/.env.example` para criar um arquivo `.env` na raiz do projeto. Preencha os campos de acordo com as especificidades.

```env
PROFILE_NAME= Perfil da AWS
ROLE_ARN= Regras para usar o Sagemaker e o S3   
DB_INSTANCE_IDENTIFIER= Instancia do banco de dados RDS
DB_INSTANCE_CLASS= Classe da instancia
DB_ENGINE= MySQL                                                    #Obrigat√≥rio ser, por causa do PyMySQL
DB_NAME= Nome do banco de dados
DB_USER= Nome do usu√°rio administrador
DB_PASSWORD= Senha do usu√°rio administrador
DB_PORT=3306                                                        #N√£o necess√°riamente esta, mas √© aconselh√°vel
DB_HOST=URL do banco de dados
DB_SUBNET_GROUP= Grupo de subredes onde a inst√¢ncia RDS ser√° criada
```


#### IV. Instale as Depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```

#### V. Rode os Scripts:
Todos os arquivos citados est√£o localizados na pasta `data/`.

- Crie a inst√¢ncia:
   ```bash
   python create_rds_instance.py
   ```

- Conecte-se ao banco:
   ```bash
   python connect_db.py
   ```

- Carregue um DataFrame do CSV para o RDS:
   ```bash
   python db_load.py
   ```

- Obtenha os dados da tabela 'reservations':
   ```bash
   python get_rds_data.py
   ```

- Prepare e armazene os dados em outra tabela:
   ```bash
   python data_prepare.py
   ```

##### Observa√ß√£o sobre o Subnet Group
√â necess√°rio criar um DB Subnet Group no RDS. Se n√£o existir uma subnet padr√£o, crie uma e adicione o par√¢metro `DBSubnetGroupName` com o nome da subnet:

```
DBSubnetGroupName: nome_da_subnet
```


#### VI. Login da AWS CLI:
Confirme que est√° com as credenciais da AWS CLI corretas para conseguir logar e executar os notebooks. Voc√™ poder√° fazer isto no arqurivo localizado na pasta `notebooks\modeling`.


#### VII. Preencha as credenciais do config:
Ap√≥s receber os valores gerados pelo notebook. Preencha a credenciais do arquivo localizado na pasta `api\src\config`.

```py
   BUCKET_NAME ='your-bucket-aws-name'
   MODEL_KEY = 'path-to-model'
   HOST = '127.0.0.1'
   PORT = 9000
   PROFILE_NAME = 'name-of-your-aws-profile'
```
#### VIII. Execute o Arquivo Principal:
```bash
   uvicorn api.src.main:app¬†--reload
```

#### IX. Crie a Execu√ß√£o Local do Docker Compose:
```bash
docker compose up -d
```

##### Observa√ß√µes Adicionais
- Configura√ß√£o do Docker Compose: Certifique-se de que o arquivo docker-compose.yml est√° configurado corretamente na raiz do projeto. Se n√£o estiver, forne√ßa instru√ß√µes para cri√°-lo.
- Ambiente Virtual: Recomenda-se criar um ambiente virtual para instalar as depend√™ncias:
```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
```
- Permiss√µes e Pol√≠ticas IAM: Verifique se o perfil da AWS tem permiss√µes adequadas para criar e gerenciar inst√¢ncias RDS, acessar S3, e outras opera√ß√µes necess√°rias.

Pronto! Agora voc√™ pode acessar sua aplica√ß√£o e v√™-la funcionar.

<h2 id="dificuldades-encontradas"> „ÄΩÔ∏è Dificuldades Encontradas </h2>

- Desenvolvimento do Ambiente Docker Compose
- Achar hiperparametros bons para alcan√ßar uma boa acur√°ci.
- Integra√ß√£o da API com o modelo.

<h2 id="contribuidores">üì´ Contribuidores</h2>

- Brian Rafael   - brian.trajano@compasso.com.br
- Ester Pequeno  - ester.trevisan@compasso.com.br
- Luiz Manoel    - luiz.dantas@compasso.com.br
- Ricardo Luiz   - ricardo.prado@compasso.com.br

###### vers√£o 0.0.1
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquivo para treinamento do modelo, inferencias e testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get root directory \n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parents[1]\n",
    "\n",
    "# Adicionando diretórios ao path do Python env\n",
    "# Adding directories to Python env path\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(str(project_root / 'data'))\n",
    "sys.path.append(str(project_root / 'data' / 'processed'))\n",
    "sys.path.append(str(project_root / 'data' / 'external'))\n",
    "sys.path.append(str(project_root / 'notebooks'))\n",
    "sys.path.append(str(project_root / 'notebooks' / 'exploratory'))\n",
    "sys.path.append(str(project_root / 'notebooks' / 'modeling'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from data.processed.data_prepare import prepared_base\n",
    "\n",
    "# Load data\n",
    "base_hotel = prepared_base\n",
    "base_hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace boolean values\n",
    "base_hotel = base_hotel.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test base split\n",
    "base_train = base_hotel.iloc[0:28000,:]\n",
    "base_test = base_hotel.iloc[28000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns 1 to 28 (inclusive) as feature variables (X_test)\n",
    "X_test = base_test.iloc[:, 1:29].values\n",
    "\n",
    "# Select column 0 as the target variable (y_test)\n",
    "y_test = base_test.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_train.shape)\n",
    "print(base_test.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing train and test csv files\n",
    "base_train_path = '../../data/raw/hotel_reservations_train_xgboost.csv'\n",
    "base_test_path = '../../data/raw/hotel_reservations_test_xgboost.csv'\n",
    "\n",
    "base_train.to_csv(base_train_path, header = False, index = False)\n",
    "base_test.to_csv(base_test_path, header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Environment Variables\n",
    "profile_name = os.getenv(\"PROFILE_NAME\")\n",
    "role_arn = os.getenv(\"ROLE_ARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session\n",
    "\n",
    "# create and configure sessions\n",
    "boto_session = boto3.Session(profile_name=profile_name)\n",
    "boto3.setup_default_session(profile_name=profile_name)\n",
    "session = sagemaker.Session(boto_session)\n",
    "role = role_arn\n",
    "\n",
    "# create bucket\n",
    "bucket_name = \"bucket-sprint5-compassuol\"\n",
    "s3_client = boto_session.client('s3')\n",
    "try:\n",
    "    response = s3_client.create_bucket(\n",
    "        Bucket=bucket_name\n",
    "    )\n",
    "    print(f\"Bucket '{bucket_name}' criado com sucesso.\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(f\"O bucket '{bucket_name}' já existe e é de sua propriedade.\")\n",
    "except s3_client.exceptions.BucketAlreadyExists:\n",
    "    print(f\"O bucket '{bucket_name}' já existe, mas não é de sua propriedade.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar o bucket: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpasta_modelo = 'modelos/hotel-reservations/xgboost'\n",
    "subpasta_dataset = 'datasets/hotel-reservations'\n",
    "key_train = 'hotel-train-data-xgboost'\n",
    "key_test = 'hotel-test-data-xgboost'\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket_name, subpasta_dataset, key_train)\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket_name, subpasta_dataset, key_test)\n",
    "output_location = 's3://{}/{}/output'.format(bucket_name, subpasta_modelo)\n",
    "\n",
    "print(output_location)\n",
    "print(role_arn)\n",
    "print(profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Csv files to S3\n",
    "import os\n",
    "with open(base_train_path, 'rb') as f:\n",
    "    s3_path = os.path.join(subpasta_dataset, 'train', key_train).replace('\\\\', '/')\n",
    "    boto_session.resource('s3').Bucket(bucket_name).Object(s3_path).upload_fileobj(f)\n",
    "    \n",
    "print(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_test_path, 'rb') as f:\n",
    "    s3_path = os.path.join(subpasta_dataset, 'test', key_test).replace('\\\\', '/')\n",
    "    boto_session.resource('s3').Bucket(bucket_name).Object(s3_path).upload_fileobj(f)\n",
    "    \n",
    "print(s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Retrieve the URI of the Docker image for the XGBoost framework\n",
    "container = image_uris.retrieve(\n",
    "    framework = 'xgboost',                 # Specify the machine learning framework (XGBoost)\n",
    "    region = boto3.Session().region_name,  # Get the current AWS region from the boto3 session\n",
    "    version = '1.7-1'                      # Specify the version of the XGBoost framework\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters for the XGBoost model\n",
    "params = {\n",
    "    'objective': 'multi:softmax',             # The learning task and objective ('multi:softmax' for multi-class classification)\n",
    "    'num_class': 3,                           # The number of classes to classify\n",
    "    'eval_metric': 'mlogloss',                # The evaluation metric to monitor during training (multiclass log-loss)\n",
    "    'gamma': '0.6307462738756113',            # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    'lambda': '0.13870950469471877',          # L2 regularization term on weights\n",
    "    'colsample_bytree': '0.9580688142306052', # Subsample ratio of columns when constructing each tree\n",
    "    'eta': '0.05375196116547447',             # Step size shrinkage to prevent overfitting (learning rate)\n",
    "    'max_depth': '9',                         # Maximum depth of a tree\n",
    "    'min_child_weight': '2.629400053328948',  # Minimum sum of instance weight needed in a child\n",
    "    'subsample': '0.9553898205800991',        # Subsample ratio of the training instance\n",
    "    'num_round': 1000                         # Number of boosting rounds\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an XGBoost Estimator object\n",
    "xgboost = sagemaker.estimator.Estimator(\n",
    "                                            image_uri = container,          # The URI of the container image for the XGBoost algorithm\n",
    "                                            role = role,                    # The AWS IAM role that SageMaker can assume to access AWS resources\n",
    "                                            instance_count = 1,             # The number of instances to use for the training job\n",
    "                                            instance_type = 'ml.m5.large',  # The type of EC2 instance to use for the training job\n",
    "                                            output_path = output_location,  # The S3 path where the model artifacts will be stored\n",
    "                                            sagemaker_session = session,    # The SageMaker session object\n",
    "                                            use_spot_instances = True,      # Whether to use Amazon EC2 Spot instances for the training job\n",
    "                                            max_run = 3600,                 # The maximum run time in seconds for the training job\n",
    "                                            max_wait = 3600,                # The maximum wait time in seconds for spot instances\n",
    "                                            hyperparameters = params        # The hyperparameters for the XGBoost algorithm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a TrainingInput object for the training data\n",
    "train_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data = s3_train_data,      # The S3 URI where the training data is stored\n",
    "    content_type = 'csv',         # The format of the training data (CSV)\n",
    "    s3_data_type = 'S3Prefix'     # The type of S3 data source (S3Prefix)\n",
    ")\n",
    "\n",
    "# Creating a TrainingInput object for the validation data\n",
    "validation_input = sagemaker.inputs.TrainingInput(\n",
    "    s3_data = s3_test_data,       # The S3 URI where the validation data is stored\n",
    "    content_type = 'csv',         # The format of the validation data (CSV)\n",
    "    s3_data_type = 'S3Prefix'     # The type of S3 data source (S3Prefix)\n",
    ")\n",
    "\n",
    "# Defining the data channels for the training job\n",
    "data_channels = {\n",
    "    'train': train_input,         # The training data channel\n",
    "    'validation': validation_input  # The validation data channel\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting training\n",
    "job = 'XGBoost-Sprint5'\n",
    "xgboost.fit(data_channels, job_name=job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "model_file_key = 'modelos/hotel-reservations/xgboost/output/XGBoost-Sprint5/output/model.tar.gz'\n",
    "local_model_path = 'model.tar.gz'\n",
    "\n",
    "# Starting S3 session\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Downloading model from s3\n",
    "s3.download_file(bucket_name, model_file_key, local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile  # Import the tarfile module for working with tar archives\n",
    "\n",
    "# Open the tar archive in read mode\n",
    "with tarfile.open(local_model_path, 'r:gz') as tar:\n",
    "    # Get a list of all files in the tar archive\n",
    "    tar_list = tar.getnames()\n",
    "    print(\"Files in the tar archive:\", tar_list)\n",
    "    \n",
    "    # Extract all files from the tar archive\n",
    "    tar.extractall()\n",
    "\n",
    "# Define the model file name\n",
    "model_file = 'xgboost-model'\n",
    "\n",
    "# Check if the model file exists\n",
    "if os.path.exists(model_file):\n",
    "    # Open the model file in binary read mode\n",
    "    with open(model_file, 'rb') as f:\n",
    "        # Read the first 4 bytes of the file to get the file header\n",
    "        file_header = f.read(4)\n",
    "        print(\"File header:\", file_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'xgboost-model'\n",
    "\n",
    "# Load model\n",
    "model = xgb.Booster()\n",
    "model.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for evaluation and visualization\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the test data into the DMatrix format required by XGBoost\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "previsoes = model.predict(dtest)\n",
    "\n",
    "# Round predictions to the nearest integer\n",
    "previsoes_rounded = np.round(previsoes).astype(int)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, previsoes_rounded)\n",
    "print(f'Acurácia: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, previsoes_rounded))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, previsoes_rounded)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "plt.xlabel('Predicted Label')  # Set the x-axis label\n",
    "plt.ylabel('True Label')       # Set the y-axis label\n",
    "plt.title('Confusion Matrix')  # Set the title of the plot\n",
    "plt.show()                     # Display the plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
